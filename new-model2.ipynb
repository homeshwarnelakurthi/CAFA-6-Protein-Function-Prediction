{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# --- MASTER TRAINING CELL (MFO - Molecular Function) ---\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\n\n# 1. LOAD & CLEAN INPUTS\nprint(\"1. Loading & Cleaning Inputs...\")\ntrain_emb = np.load(\"/kaggle/input/emb-models-ttt/train_embeds.npy\").astype(np.float32)\ntrain_ids = np.load(\"/kaggle/input/emb-models-ttt/train_ids.npy\")\ntest_emb = np.load(\"/kaggle/input/emb-models-ttt/test_embeds.npy\").astype(np.float32)\ntest_ids = np.load(\"/kaggle/input/emb-models-ttt/test_ids.npy\")\n\n# Standard Scale Inputs (Crucial for convergence)\nmean = train_emb.mean(axis=0)\nstd = train_emb.std(axis=0) + 1e-6\ntrain_emb = (train_emb - mean) / std\ntest_emb = (test_emb - mean) / std\nprint(f\"   Inputs ready. Shape: {train_emb.shape}\")\n\n# 2. LOAD & BUILD LABELS\nprint(\"2. Building Labels (Target: Function 'F')...\")\nterms_df = pd.read_csv(CONFIG[\"paths\"][\"train_terms\"], sep=\"\\t\", header=None, names=[\"id\", \"term\", \"aspect\"])\n\n# Filter for Molecular Function (F)\n# Note: In this file, aspect is 'F', not 'MFO'\nTARGET_ASPECT = 'F' \naspect_terms = terms_df[terms_df['aspect'] == TARGET_ASPECT]\n\n# Get Top 1500 Terms\ntop_terms = aspect_terms['term'].value_counts().index[:1500].tolist()\nterm_map = {t: i for i, t in enumerate(top_terms)}\nnum_classes = len(top_terms)\n\n# Build Matrix\nlabel_matrix = np.zeros((len(train_ids), num_classes), dtype=np.float32)\nid_map = {pid: i for i, pid in enumerate(train_ids)}\nrelevant_rows = aspect_terms[aspect_terms['term'].isin(top_terms)]\n\nfor _, row in tqdm(relevant_rows.iterrows(), total=len(relevant_rows), desc=\"Mapping Labels\"):\n    if row['id'] in id_map:\n        label_matrix[id_map[row['id']], term_map[row['term']]] = 1.0\n\nprint(f\"   Labels ready. Shape: {label_matrix.shape}\")\n\n# 3. DEFINE MODEL (Simple & Robust)\nclass CAFA_MLP(nn.Module):\n    def __init__(self, n_features, n_classes):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_features, 512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, n_classes)\n        )\n    def forward(self, x):\n        return self.net(x)\n\n# 4. TRAIN\nprint(\"3. Starting Training...\")\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Dataset\nclass ProteinData(Dataset):\n    def __init__(self, X, y):\n        self.X = torch.from_numpy(X)\n        self.y = torch.from_numpy(y)\n    def __len__(self): return len(self.X)\n    def __getitem__(self, i): return self.X[i], self.y[i]\n\n# Split 90/10\nperm = np.random.permutation(len(train_ids))\nsplit = int(len(train_ids) * 0.9)\ntrain_ds = ProteinData(train_emb[perm[:split]], label_matrix[perm[:split]])\nval_ds = ProteinData(train_emb[perm[split:]], label_matrix[perm[split:]])\n\ntrain_loader = DataLoader(train_ds, batch_size=256, shuffle=True)\nval_loader = DataLoader(val_ds, batch_size=256)\n\n# Init\nmodel = CAFA_MLP(1280, num_classes).to(device)\nopt = torch.optim.Adam(model.parameters(), lr=1e-3)\nloss_fn = nn.BCEWithLogitsLoss()\n\n# Loop\nfor epoch in range(15):\n    model.train()\n    total_loss = 0\n    for x, y in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n        x, y = x.to(device), y.to(device)\n        opt.zero_grad()\n        pred = model(x)\n        loss = loss_fn(pred, y)\n        loss.backward()\n        opt.step()\n        total_loss += loss.item()\n    \n    print(f\"Epoch {epoch+1} Loss: {total_loss/len(train_loader):.4f}\")\n\n# Save\ntorch.save(model.state_dict(), \"model_MFO.pth\")\nprint(\"Training Complete. Model Saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:22:29.636962Z","iopub.execute_input":"2025-11-30T06:22:29.637621Z","iopub.status.idle":"2025-11-30T06:22:55.491671Z","shell.execute_reply.started":"2025-11-30T06:22:29.637601Z","shell.execute_reply":"2025-11-30T06:22:55.490985Z"}},"outputs":[{"name":"stdout","text":"1. Loading & Cleaning Inputs...\n   Inputs ready. Shape: (82404, 1280)\n2. Building Labels (Target: Function 'F')...\n","output_type":"stream"},{"name":"stderr","text":"Mapping Labels: 100%|██████████| 112061/112061 [00:04<00:00, 23774.87it/s]\n","output_type":"stream"},{"name":"stdout","text":"   Labels ready. Shape: (82404, 1500)\n3. Starting Training...\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 290/290 [00:01<00:00, 239.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 Loss: 0.0186\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 290/290 [00:01<00:00, 256.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 Loss: 0.0045\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 290/290 [00:01<00:00, 249.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 Loss: 0.0041\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 290/290 [00:01<00:00, 226.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 Loss: 0.0038\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 290/290 [00:01<00:00, 253.49it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 Loss: 0.0035\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 290/290 [00:01<00:00, 257.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 Loss: 0.0033\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 290/290 [00:01<00:00, 232.04it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 Loss: 0.0032\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 290/290 [00:01<00:00, 260.98it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8 Loss: 0.0031\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 290/290 [00:01<00:00, 255.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9 Loss: 0.0030\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 290/290 [00:01<00:00, 249.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10 Loss: 0.0029\n","output_type":"stream"},{"name":"stderr","text":"Epoch 11: 100%|██████████| 290/290 [00:01<00:00, 217.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11 Loss: 0.0028\n","output_type":"stream"},{"name":"stderr","text":"Epoch 12: 100%|██████████| 290/290 [00:01<00:00, 248.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12 Loss: 0.0028\n","output_type":"stream"},{"name":"stderr","text":"Epoch 13: 100%|██████████| 290/290 [00:01<00:00, 248.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13 Loss: 0.0027\n","output_type":"stream"},{"name":"stderr","text":"Epoch 14: 100%|██████████| 290/290 [00:01<00:00, 250.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14 Loss: 0.0027\n","output_type":"stream"},{"name":"stderr","text":"Epoch 15: 100%|██████████| 290/290 [00:01<00:00, 218.40it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 15 Loss: 0.0026\nTraining Complete. Model Saved!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# --- GENERATE SUBMISSION ---\nprint(\"Generating Submission...\")\nmodel.eval()\n\npreds = []\nbatch_size = 1024 # Fast inference\ntest_loader = DataLoader(torch.from_numpy(test_emb), batch_size=batch_size)\n\nwith torch.no_grad():\n    for x in tqdm(test_loader, desc=\"Predicting\"):\n        x = x.to(device)\n        # Forward pass\n        logits = model(x)\n        # Sigmoid to get probabilities (0 to 1)\n        probs = torch.sigmoid(logits).cpu().numpy()\n        preds.append(probs)\n\n# Combine all batches\nall_probs = np.vstack(preds)\nprint(f\"Predictions Shape: {all_probs.shape}\") # (Test_Size, 1500)\n\n# Write to TSV file\nprint(\"Writing submission.tsv...\")\nwith open(\"submission.tsv\", \"w\") as f:\n    # Header is not strictly needed for CAFA but good practice\n    # Format: ProteinID <tab> GO_Term <tab> Score\n    \n    for i, pid in enumerate(tqdm(test_ids)):\n        # Get top 50 predictions per protein to save space\n        # (Most proteins only have a few functions)\n        row_probs = all_probs[i]\n        # Get indices of top 50 scores\n        top_indices = np.argpartition(row_probs, -50)[-50:]\n        \n        for idx in top_indices:\n            score = row_probs[idx]\n            # Only keep scores > 0.01 (filtering low confidence)\n            if score > 0.01:\n                term = top_terms[idx]\n                # Format: <ProteinID> <GO_Term> <Score>\n                f.write(f\"{pid}\\t{term}\\t{score:.3f}\\n\")\n\nprint(\"✅ submission.tsv created!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T06:24:01.851179Z","iopub.execute_input":"2025-11-30T06:24:01.851701Z","iopub.status.idle":"2025-11-30T06:24:34.108130Z","shell.execute_reply.started":"2025-11-30T06:24:01.851668Z","shell.execute_reply":"2025-11-30T06:24:34.107374Z"}},"outputs":[{"name":"stdout","text":"Generating Submission...\n","output_type":"stream"},{"name":"stderr","text":"Predicting: 100%|██████████| 220/220 [00:02<00:00, 102.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Predictions Shape: (224309, 1500)\nWriting submission.tsv...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 224309/224309 [00:29<00:00, 7553.02it/s]","output_type":"stream"},{"name":"stdout","text":"✅ submission.tsv created!\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}